import json
import pymysql
from pymysql.err import OperationalError, IntegrityError, ProgrammingError

# -------------------------- é…ç½®é¡¹ --------------------------
DB_CONFIG = {
    "host": "localhost",
    "port": 3306,
    "user": "root",
    "password": "hyw499",
    "database": "niche_ reviews",  # æ³¨æ„æ•°æ®åº“åæ˜¯å¦ä¸è¡¨ç»“æ„ä¸€è‡´
    "charset": "utf8mb4"
}

JSON_FILE_PATH = "business.json"

FOOD_DRINK_KEYWORDS = {
    "Restaurants", "Food", "Coffee & Tea", "Bars", "Bakeries", "Desserts",
    "Fast Food", "Pizza", "Chinese", "Italian", "Japanese", "Cafes",
    "Ice Cream & Frozen Yogurt", "Juice Bars & Smoothies", "Beer", "Wine & Spirits"
}

BATCH_SIZE = 1000
# -------------------------------------------------------------


def connect_mysql():
    """å»ºç«‹MySQLæ•°æ®åº“è¿æ¥"""
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        return conn, cursor
    except OperationalError as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
        raise SystemExit(1)


def process_business_data():
    """å¤„ç†Yelpæ•°æ®å¹¶å¯¼å…¥MySQL"""
    conn, cursor = connect_mysql()
    batch_data = []  # æ‰¹é‡å­˜å‚¨å¾…æ’å…¥æ•°æ®

    try:
        with open(JSON_FILE_PATH, "r", encoding="utf8") as f:
            total_count = 0
            import_count = 0
            skip_count = 0

            for line_num, line in enumerate(f, start=1):
                try:
                    data = json.loads(line.strip())
                    total_count += 1

                    # ç­›é€‰é¤é¥®ç±»åˆ«å•†é“º
                    categories = data.get("categories")
                    if not categories:
                        skip_count += 1
                        continue

                    category_list = [cat.strip().lower() for cat in categories.split(",")]
                    food_keywords_lower = {keyword.lower() for keyword in FOOD_DRINK_KEYWORDS}
                    if not any(keyword in category_list for keyword in food_keywords_lower):
                        skip_count += 1
                        continue

                    # å¤„ç†å­—æ®µï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šå°†åŸbusiness_idå­˜å…¥bidå­—æ®µï¼‰
                    bid = data.get("business_id")  # åŸæ•°æ®ä¸­çš„å­—ç¬¦ä¸²ID
                    if not bid:
                        skip_count += 1
                        continue

                    # å¿…é€‰å­—æ®µ
                    name = data.get("name") or "Unknown"
                    address = data.get("address") or "Unknown"
                    city = data.get("city") or "Unknown"
                    state = data.get("state") or "Unknown"
                    stars = data.get("stars") or 0.0
                    review_count = data.get("review_count") or 0

                    # å¯é€‰å­—æ®µ
                    postal_code = data.get("postal_code")
                    latitude = data.get("latitude")
                    longitude = data.get("longitude")
                    is_open = data.get("is_open") if data.get("is_open") is not None else 1

                    # JSONå­—æ®µ
                    attributes = json.dumps(data.get("attributes", {})) if data.get("attributes") else None
                    hours = json.dumps(data.get("hours", {})) if data.get("hours") else None

                    # æ”¶é›†æ‰¹é‡æ•°æ®ï¼ˆä¸å†åŒ…å«è‡ªå¢çš„business_idï¼Œæ–°å¢bidå­—æ®µï¼‰
                    batch_data.append((
                        name, address, city, state, postal_code, latitude, longitude,
                        stars, review_count, is_open, categories, attributes, hours, bid
                    ))

                    if len(batch_data) >= BATCH_SIZE:
                        batch_insert(cursor, batch_data)
                        import_count += len(batch_data)
                        batch_data = []
                        print(f"ğŸ”„ å·²å¤„ç†{total_count}æ¡ï¼Œå¯¼å…¥{import_count}æ¡ï¼Œè·³è¿‡{skip_count}æ¡...")

                except json.JSONDecodeError as e:
                    print(f"âš ï¸ ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥ï¼š{e}ï¼Œè·³è¿‡è¯¥è¡Œ")
                    skip_count += 1
                    continue
                except Exception as e:
                    print(f"âš ï¸ ç¬¬{line_num}è¡Œå¤„ç†å¼‚å¸¸ï¼š{e}ï¼Œè·³è¿‡è¯¥è¡Œ")
                    skip_count += 1
                    continue

            if batch_data:
                batch_insert(cursor, batch_data)
                import_count += len(batch_data)

            conn.commit()
            print("\n" + "="*50)
            print(f"ğŸ“Š å¤„ç†å®Œæˆï¼")
            print(f"æ€»æ•°æ®æ¡æ•°ï¼š{total_count}")
            print(f"æˆåŠŸå¯¼å…¥æ¡æ•°ï¼š{import_count}")
            print(f"è·³è¿‡æ¡æ•°ï¼š{skip_count}")
            print("="*50)

    except Exception as e:
        conn.rollback()
        print(f"âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥ï¼Œäº‹åŠ¡å›æ»šï¼š{e}")
    finally:
        cursor.close()
        conn.close()
        print("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")


def batch_insert(cursor, batch_data):
    """æ‰¹é‡æ’å…¥æ•°æ®ï¼ˆä¿®æ­£SQLå­—æ®µï¼ŒåŒ¹é…è¡¨ç»“æ„ï¼‰"""
    insert_sql = """
    INSERT INTO `business` (
        name, address, city, state, postal_code, latitude, longitude,
        stars, review_count, is_open, categories, attributes, hours, bid
    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    ON DUPLICATE KEY UPDATE updated_at = CURRENT_TIMESTAMP;
    """
    try:
        cursor.executemany(insert_sql, batch_data)
    except IntegrityError as e:
        print(f"âš ï¸ æ‰¹é‡æ’å…¥å†²çªï¼ˆä¸»é”®é‡å¤ï¼‰ï¼š{e}ï¼Œè·³è¿‡é‡å¤æ•°æ®")
    except ProgrammingError as e:
        print(f"âš ï¸ SQLè¯­æ³•é”™è¯¯ï¼š{e}")
        raise


if __name__ == "__main__":
    process_business_data()